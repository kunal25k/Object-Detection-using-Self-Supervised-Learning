{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"segmentation.ipynb","provenance":[{"file_id":"1qISJ1COiGNcy3klY79E7sJG1Sk7xtjYk","timestamp":1650768659040}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBaNWm95N-Ml","executionInfo":{"status":"ok","timestamp":1651142387976,"user_tz":240,"elapsed":13162,"user":{"displayName":"Sai Charitha Akula","userId":"07906439284563601887"}},"outputId":"5c7a31e7-1235-46da-9682-a76cada045d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["#%$root_path = 'gdrive/My\\ Drive/collabnotebooks/dlproject'\n","#%ls\n","#%cd gdrive/MyDrive/\n","#%ls\n","#%cd MyDrive/\n","#%cd /gdrive/MyDrive/colabnotebooks/\n","#%ls\n","#%cd dlproject/\n","#%ls\n","%ls\n","%cd gdrive/MyDrive/colabnotebooks/dlproject/semsslproject2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YuKF_2afrmT","executionInfo":{"status":"ok","timestamp":1651142390038,"user_tz":240,"elapsed":496,"user":{"displayName":"Sai Charitha Akula","userId":"07906439284563601887"}},"outputId":"fbc39e4c-acee-43fb-e3ab-b0c4c856540c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n","/content/gdrive/MyDrive/colabnotebooks/dlproject/semsslproject2\n"]}]},{"cell_type":"code","source":["pip install -U PyYAML"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-4jlsEjizg2","executionInfo":{"status":"ok","timestamp":1651142396413,"user_tz":240,"elapsed":4570,"user":{"displayName":"Sai Charitha Akula","userId":"07906439284563601887"}},"outputId":"51af94ff-cffe-4902-d7b4-f4c6aaa128fb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n","Collecting PyYAML\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: PyYAML\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0\n"]}]},{"cell_type":"code","source":["#!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"],"metadata":{"id":"_GSUD3W3i_BD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Copyright 2021 DeepMind Technologies Limited\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#    http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","\n","r\"\"\"Converts raw ImageNet data to TFRecords with Felzenzwalb segmentations.\n","\n","The raw ImageNet data set is expected to reside in JPEG files located in the\n","following directory structure.\n","\n","  data_dir/n01440764/ILSVRC2012_val_00000293.JPEG\n","  data_dir/n01440764/ILSVRC2012_val_00000543.JPEG\n","  ...\n","\n","where 'n01440764' is the unique synset label associated with\n","these images.\n","\n","The training data set consists of 1000 sub-directories (i.e. labels)\n","each containing 1200 JPEG images for a total of 1.2M JPEG images.\n","\n","The evaluation data set consists of 1000 sub-directories (i.e. labels)\n","each containing 50 JPEG images for a total of 50K JPEG images.\n","\n","This TensorFlow script converts the training and evaluation data into\n","a sharded data set consisting of 1024 and 128 TFRecord files, respectively.\n","\n","  train_directory/train-00000-of-01024\n","  train_directory/train-00001-of-01024\n","  ...\n","  train_directory/train-00127-of-01024\n","\n","and\n","\n","  validation_directory/validation-00000-of-00128\n","  validation_directory/validation-00001-of-00128\n","  ...\n","  validation_directory/validation-00127-of-00128\n","\n","Each validation TFRecord file contains ~390 records. Each training TFREcord\n","file contains ~1250 records. Each record within the TFRecord file is a\n","serialized Example proto. The Example proto contains the following fields:\n","\n","  image/encoded: string containing JPEG encoded image in RGB colorspace\n","  image/height: integer, image height in pixels\n","  image/width: integer, image width in pixels\n","  image/colorspace: string, specifying the colorspace, always 'RGB'\n","  image/channels: integer, specifying the number of channels, always 3\n","  image/format: string, specifying the format, always'JPEG'\n","\n","  image/filename: string containing the basename of the image file\n","            e.g. 'n01440764_10026.JPEG' or 'ILSVRC2012_val_00000293.JPEG'\n","  image/class/label: integer specifying the index in a classification layer.\n","    The label ranges from [1, 1000] where 0 is not used.\n","  image/class/synset: string specifying the unique ID of the label,\n","    e.g. 'n01440764'\n","  image/class/text: string specifying the human-readable version of the label\n","    e.g. 'red fox, Vulpes vulpes'\n","\n","Note that the length of xmin is identical to the length of xmax, ymin and ymax\n","for each example.\n","\n","Sample command to run:\n","  python generate_fh_masks_for_imagenet.py -- \\\n","  --validation_directory=/tmp/imagenet-val \\\n","  --output_directory=/tmp/imagenet-val-fh\n","\"\"\"\n","\n","from datetime import datetime  # pylint: disable=g-importing-member\n","import os\n","import random\n","import sys\n","import threading\n","\n","import numpy as np\n","from six.moves import xrange  # pylint: disable=redefined-builtin\n","import skimage.segmentation\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","\n","\n","tf.app.flags.DEFINE_string('train_directory', None,\n","                           'Training data directory')\n","\n","tf.app.flags.DEFINE_string('validation_directory', None,\n","                           'Validation data directory')\n","\n","tf.app.flags.DEFINE_string('output_directory', None,\n","                           'Output data directory')\n","\n","tf.app.flags.DEFINE_integer('train_shards', 2048,\n","                            'Number of shards in training TFRecord files.')\n","\n","tf.app.flags.DEFINE_integer('validation_shards', 256,\n","                            'Number of shards in validation TFRecord files.')\n","\n","tf.app.flags.DEFINE_integer('num_threads', 16,\n","                            'Number of threads to preprocess the images.')\n","\n","tf.app.flags.DEFINE_string('fh_scales', '1000',\n","                           'Felzenszwalb segment scales, comma separated.')\n","tf.app.flags.DEFINE_string('fh_min_sizes', '1000',\n","                           'Felzenszwalb group sizes.')\n","\n","# The labels file contains a list of valid labels are held in this file.\n","# Assumes that the file contains entries as such:\n","#   n01440764\n","#   n01443537\n","#   n01484850\n","# where each line corresponds to a label expressed as a synset. We map\n","# each synset contained in the file to an integer (based on the alphabetical\n","# ordering). See below for details.\n","tf.app.flags.DEFINE_string('labels_file',\n","                           'imagenet_lsvrc_2015_synsets.txt',\n","                           'Labels file')\n","\n","# This file containing mapping from synset to human-readable label.\n","# Assumes each line of the file looks like:\n","#\n","#   n02119247    black fox\n","#   n02119359    silver fox\n","#   n02119477    red fox, Vulpes fulva\n","#\n","# where each line corresponds to a unique mapping. Note that each line is\n","# formatted as <synset>\\t<human readable label>.\n","tf.app.flags.DEFINE_string('imagenet_metadata_file',\n","                           'imagenet_metadata.txt',\n","                           'ImageNet metadata file')\n","\n","FLAGS = tf.app.flags.FLAGS\n","\n","\n","def _int64_feature(value):\n","  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n","  if not isinstance(value, list):\n","    value = [value]\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n","\n","\n","def _float_feature(value):\n","  \"\"\"Wrapper for inserting float features into Example proto.\"\"\"\n","  if not isinstance(value, list):\n","    value = [value]\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n","\n","\n","def _bytes_feature(value):\n","  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _convert_to_example(filename, image_buffer, fh_masks, label, synset, human,\n","                        height, width):\n","  \"\"\"Build an Example proto for an example.\n","\n","  Args:\n","    filename: string, path to an image file, e.g., '/path/to/example.JPG'\n","    image_buffer: string, JPEG encoding of RGB image\n","    fh_masks: the Felzenzwalb image segmentations corresponding to the image.\n","    label: integer, identifier for the ground truth for the network\n","    synset: string, unique WordNet ID specifying the label, e.g., 'n02323233'\n","    human: string, human-readable label, e.g., 'red fox, Vulpes vulpes'\n","    height: integer, image height in pixels\n","    width: integer, image width in pixels\n","  Returns:\n","    Example proto\n","  \"\"\"\n","\n","  colorspace = b'RGB'\n","  channels = 3\n","  image_format = b'JPEG'\n","  base_filename = os.path.basename(filename)\n","  bytes_fh_masks = fh_masks.reshape([-1]).tobytes()\n","\n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image/height': _int64_feature(height),\n","      'image/width': _int64_feature(width),\n","      'image/colorspace': _bytes_feature(colorspace),\n","      'image/channels': _int64_feature(channels),\n","      'image/class/label': _int64_feature(label),\n","      'image/class/synset': _bytes_feature(bytes(synset, 'utf-8')),\n","      'image/class/text': _bytes_feature(bytes(human, 'utf-8')),\n","      'image/format': _bytes_feature(image_format),\n","      'image/filename': _bytes_feature(bytes(base_filename, 'utf-8')),\n","      'image/encoded': _bytes_feature(image_buffer),\n","      'image/felzenszwalb_segmentations': _bytes_feature(bytes_fh_masks),\n","  }))\n","  return example\n","\n","\n","class ImageCoder(object):\n","  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n","\n","  def __init__(self):\n","    # Create a single Session to run all image coding calls.\n","    self._sess = tf.Session()\n","\n","    # Initializes function that converts PNG to JPEG data.\n","    self._png_data = tf.placeholder(dtype=tf.string)\n","    image = tf.image.decode_png(self._png_data, channels=3)\n","    self._png_to_jpeg = tf.image.encode_jpeg(image, format='rgb', quality=100)\n","\n","    # Initializes function that converts CMYK JPEG data to RGB JPEG data.\n","    self._cmyk_data = tf.placeholder(dtype=tf.string)\n","    image = tf.image.decode_jpeg(self._cmyk_data, channels=0)\n","    self._cmyk_to_rgb = tf.image.encode_jpeg(image, format='rgb', quality=100)\n","\n","    # Initializes function that decodes RGB JPEG data.\n","    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n","    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n","\n","  def png_to_jpeg(self, image_data):\n","    return self._sess.run(self._png_to_jpeg,\n","                          feed_dict={self._png_data: image_data})\n","\n","  def cmyk_to_rgb(self, image_data):\n","    return self._sess.run(self._cmyk_to_rgb,\n","                          feed_dict={self._cmyk_data: image_data})\n","\n","  def decode_jpeg(self, image_data):\n","    image = self._sess.run(self._decode_jpeg,\n","                           feed_dict={self._decode_jpeg_data: image_data})\n","    assert len(image.shape) == 3\n","    assert image.shape[2] == 3\n","    return image\n","\n","\n","def _is_png(filename):\n","  \"\"\"Determine if a file contains a PNG format image.\n","\n","  Args:\n","    filename: string, path of the image file.\n","\n","  Returns:\n","    boolean indicating if the image is a PNG.\n","  \"\"\"\n","  # File list from:\n","  # https://groups.google.com/forum/embed/?place=forum/torch7#!topic/torch7/fOSTXHIESSU\n","  return 'n02105855_2933.JPEG' in filename\n","\n","\n","def _is_cmyk(filename):\n","  \"\"\"Determine if file contains a CMYK JPEG format image.\n","\n","  Args:\n","    filename: string, path of the image file.\n","\n","  Returns:\n","    boolean indicating if the image is a JPEG encoded with CMYK color space.\n","  \"\"\"\n","  # File list from:\n","  # https://github.com/cytsai/ilsvrc-cmyk-image-list\n","  cmyk_excluded = ['n01739381_1309.JPEG', 'n02077923_14822.JPEG',\n","                   'n02447366_23489.JPEG', 'n02492035_15739.JPEG',\n","                   'n02747177_10752.JPEG', 'n03018349_4028.JPEG',\n","                   'n03062245_4620.JPEG', 'n03347037_9675.JPEG',\n","                   'n03467068_12171.JPEG', 'n03529860_11437.JPEG',\n","                   'n03544143_17228.JPEG', 'n03633091_5218.JPEG',\n","                   'n03710637_5125.JPEG', 'n03961711_5286.JPEG',\n","                   'n04033995_2932.JPEG', 'n04258138_17003.JPEG',\n","                   'n04264628_27969.JPEG', 'n04336792_7448.JPEG',\n","                   'n04371774_5854.JPEG', 'n04596742_4225.JPEG',\n","                   'n07583066_647.JPEG', 'n13037406_4650.JPEG']\n","  return filename.split('/')[-1] in cmyk_excluded\n","\n","\n","def compute_fh_segmentation(image_np, scale, min_size):\n","  \"\"\"Compute FSZ segmentation on image and record stats.\"\"\"\n","  segmented_image = skimage.segmentation.felzenszwalb(\n","      image_np, scale=scale, min_size=min_size)\n","  segmented_image = segmented_image.astype(np.dtype('<u1'))\n","  return segmented_image\n","\n","\n","def _process_image(filename, coder, fh_scales, fh_min_sizes):\n","  \"\"\"Process a single image file.\n","\n","  Args:\n","    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n","    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n","    fh_scales: Felzenzwalb-Huttenlocher segmentation scales.\n","    fh_min_sizes: Felzenzwalb-Huttenlocher min segment sizes.\n","  Returns:\n","    image_buffer: string, JPEG encoding of RGB image.\n","    height: integer, image height in pixels.\n","    width: integer, image width in pixels.\n","  \"\"\"\n","  # Read the image file.\n","  image_data = tf.gfile.GFile(filename, 'rb').read()\n","\n","  # Clean the dirty data.\n","  if _is_png(filename):\n","    # 1 image is a PNG.\n","    print('Converting PNG to JPEG for %s' % filename)\n","    image_data = coder.png_to_jpeg(image_data)\n","  elif _is_cmyk(filename):\n","    # 22 JPEG images are in CMYK colorspace.\n","    print('Converting CMYK to RGB for %s' % filename)\n","    image_data = coder.cmyk_to_rgb(image_data)\n","\n","  # Decode the RGB JPEG.\n","  image = coder.decode_jpeg(image_data)\n","\n","  fh_segmentations = []\n","  for i, fh_scale in enumerate(fh_scales):\n","    fh = compute_fh_segmentation(image, fh_scale, fh_min_sizes[i])\n","    fh_segmentations.append(fh)\n","  fh_segmentations = np.stack(fh_segmentations)\n","\n","  # Check that image converted to RGB\n","  assert len(image.shape) == 3\n","  height = image.shape[0]\n","  width = image.shape[1]\n","  assert image.shape[2] == 3\n","\n","  return image_data, fh_segmentations, height, width\n","\n","\n","def _process_image_files_batch(coder, thread_index, ranges, name, filenames,\n","                               synsets, labels, humans, num_shards,\n","                               fh_scales, fh_min_sizes):\n","  \"\"\"Processes and saves list of images as TFRecord in 1 thread.\n","\n","  Args:\n","    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n","    thread_index: integer, unique batch to run index is within [0, len(ranges)).\n","    ranges: list of pairs of integers specifying ranges of each batches to\n","      analyze in parallel.\n","    name: string, unique identifier specifying the data set\n","    filenames: list of strings; each string is a path to an image file\n","    synsets: list of strings; each string is a unique WordNet ID\n","    labels: list of integer; each integer identifies the ground truth\n","    humans: list of strings; each string is a human-readable label\n","    num_shards: integer number of shards for this data set.\n","    fh_scales: Felzenzwalb-Huttenlocher segmentation scales.\n","    fh_min_sizes: Felzenzwalb-Huttenlocher min segment sizes.\n","  \"\"\"\n","  # Each thread produces N shards where N = int(num_shards / num_threads).\n","  # For instance, if num_shards = 128, and the num_threads = 2, then the first\n","  # thread would produce shards [0, 64).\n","  num_threads = len(ranges)\n","  assert not num_shards % num_threads\n","  num_shards_per_batch = int(num_shards / num_threads)\n","\n","  shard_ranges = np.linspace(ranges[thread_index][0],\n","                             ranges[thread_index][1],\n","                             num_shards_per_batch + 1).astype(int)\n","  num_files_in_thread = ranges[thread_index][1] - ranges[thread_index][0]\n","\n","  counter = 0\n","  for s in xrange(num_shards_per_batch):\n","    # Generate a sharded version of the file name, e.g. 'train-00002-of-00010'\n","    shard = thread_index * num_shards_per_batch + s\n","    output_filename = '%s-%.5d-of-%.5d' % (name, shard, num_shards)\n","    output_file = os.path.join(FLAGS.output_directory, output_filename)\n","    writer = tf.python_io.TFRecordWriter(output_file)\n","\n","    shard_counter = 0\n","    files_in_shard = np.arange(shard_ranges[s], shard_ranges[s + 1], dtype=int)\n","    for i in files_in_shard:\n","      filename = filenames[i]\n","      label = labels[i]\n","      synset = synsets[i]\n","      human = humans[i]\n","\n","      image_buffer, fh_masks, height, width = _process_image(\n","          filename, coder, fh_scales, fh_min_sizes)\n","\n","      example = _convert_to_example(filename, image_buffer, fh_masks, label,\n","                                    synset, human, height, width)\n","      writer.write(example.SerializeToString())\n","      shard_counter += 1\n","      counter += 1\n","\n","      if not counter % 1000:\n","        print('%s [thread %d]: Processed %d of %d images in thread batch.' %\n","              (datetime.now(), thread_index, counter, num_files_in_thread))\n","        sys.stdout.flush()\n","\n","    writer.close()\n","    print('%s [thread %d]: Wrote %d images to %s' %\n","          (datetime.now(), thread_index, shard_counter, output_file))\n","    sys.stdout.flush()\n","    shard_counter = 0\n","  print('%s [thread %d]: Wrote %d images to %d shards.' %\n","        (datetime.now(), thread_index, counter, num_files_in_thread))\n","  sys.stdout.flush()\n","\n","\n","def _process_image_files(name, filenames, synsets, labels, humans, num_shards,\n","                         fh_scales, fh_min_sizes):\n","  \"\"\"Process and save list of images as TFRecord of Example protos.\n","\n","  Args:\n","    name: string, unique identifier specifying the data set\n","    filenames: list of strings; each string is a path to an image file\n","    synsets: list of strings; each string is a unique WordNet ID\n","    labels: list of integer; each integer identifies the ground truth\n","    humans: list of strings; each string is a human-readable label\n","    num_shards: integer number of shards for this data set.\n","    fh_scales: Felzenzwalb-Huttenlocher segmentation scales.\n","    fh_min_sizes: Felzenzwalb-Huttenlocher min segment sizes.\n","  \"\"\"\n","  assert len(filenames) == len(synsets)\n","  assert len(filenames) == len(labels)\n","  assert len(filenames) == len(humans)\n","\n","  # Break all images into batches with a [ranges[i][0], ranges[i][1]].\n","  spacing = np.linspace(0, len(filenames), FLAGS.num_threads + 1).astype(np.int)\n","  ranges = []\n","  threads = []\n","  for i in xrange(len(spacing) - 1):\n","    ranges.append([spacing[i], spacing[i+1]])\n","\n","  # Launch a thread for each batch.\n","  print('Launching %d threads for spacings: %s' % (FLAGS.num_threads, ranges))\n","  sys.stdout.flush()\n","\n","  # Create a mechanism for monitoring when all threads are finished.\n","  coord = tf.train.Coordinator()\n","\n","  # Create a generic TensorFlow-based utility for converting all image codings.\n","  coder = ImageCoder()\n","\n","  threads = []\n","  for thread_index in xrange(len(ranges)):\n","    args = (coder, thread_index, ranges, name, filenames,\n","            synsets, labels, humans, num_shards, fh_scales, fh_min_sizes)\n","    t = threading.Thread(target=_process_image_files_batch, args=args)\n","    t.start()\n","    threads.append(t)\n","\n","  # Wait for all the threads to terminate.\n","  coord.join(threads)\n","  print('%s: Finished writing all %d images in data set.' %\n","        (datetime.now(), len(filenames)))\n","  sys.stdout.flush()\n","\n","\n","def _find_image_files(data_dir, labels_file):\n","  \"\"\"Build a list of all images files and labels in the data set.\n","\n","  Args:\n","    data_dir: string, path to the root directory of images.\n","\n","      Assumes that the ImageNet data set resides in JPEG files located in\n","      the following directory structure.\n","\n","        data_dir/n01440764/ILSVRC2012_val_00000293.JPEG\n","        data_dir/n01440764/ILSVRC2012_val_00000543.JPEG\n","\n","      where 'n01440764' is the unique synset label associated with these images.\n","\n","    labels_file: string, path to the labels file.\n","\n","      The list of valid labels are held in this file. Assumes that the file\n","      contains entries as such:\n","        n01440764\n","        n01443537\n","        n01484850\n","      where each line corresponds to a label expressed as a synset. We map\n","      each synset contained in the file to an integer (based on the alphabetical\n","      ordering) starting with the integer 1 corresponding to the synset\n","      contained in the first line.\n","\n","      The reason we start the integer labels at 1 is to reserve label 0 as an\n","      unused background class.\n","\n","  Returns:\n","    filenames: list of strings; each string is a path to an image file.\n","    synsets: list of strings; each string is a unique WordNet ID.\n","    labels: list of integer; each integer identifies the ground truth.\n","  \"\"\"\n","  print('Determining list of input files and labels from %s.' % data_dir)\n","  challenge_synsets = [\n","      l.strip() for l in tf.gfile.GFile(labels_file, 'r').readlines()\n","  ]\n","\n","  labels = []\n","  filenames = []\n","  synsets = []\n","\n","  # Leave label index 0 empty as a background class.\n","  label_index = 1\n","\n","  # Construct the list of JPEG files and labels.\n","  for synset in challenge_synsets:\n","    jpeg_file_path = '%s/%s/*.JPEG' % (data_dir, synset)\n","    matching_files = tf.gfile.Glob(jpeg_file_path)\n","\n","    labels.extend([label_index] * len(matching_files))\n","    synsets.extend([synset] * len(matching_files))\n","    filenames.extend(matching_files)\n","\n","    if not label_index % 100:\n","      print('Finished finding files in %d of %d classes.' % (\n","          label_index, len(challenge_synsets)))\n","    label_index += 1\n","\n","  # Shuffle the ordering of all image files in order to guarantee\n","  # random ordering of the images with respect to label in the\n","  # saved TFRecord files. Make the randomization repeatable.\n","  shuffled_index = range(len(filenames))\n","  random.seed(12345)\n","  random.shuffle(list(range(len(shuffled_index))))\n","\n","  filenames = [filenames[i] for i in shuffled_index]\n","  synsets = [synsets[i] for i in shuffled_index]\n","  labels = [labels[i] for i in shuffled_index]\n","\n","  print('Found %d JPEG files across %d labels inside %s.' %\n","        (len(filenames), len(challenge_synsets), data_dir))\n","  return filenames, synsets, labels\n","\n","\n","def _find_human_readable_labels(synsets, synset_to_human):\n","  \"\"\"Build a list of human-readable labels.\n","\n","  Args:\n","    synsets: list of strings; each string is a unique WordNet ID.\n","    synset_to_human: dict of synset to human labels, e.g.,\n","      'n02119022' --> 'red fox, Vulpes vulpes'\n","\n","  Returns:\n","    List of human-readable strings corresponding to each synset.\n","  \"\"\"\n","  humans = []\n","  for s in synsets:\n","    assert s in synset_to_human, ('Failed to find: %s' % s)\n","    humans.append(synset_to_human[s])\n","  return humans\n","\n","\n","def _process_dataset(name, directory, num_shards, synset_to_human,\n","                     fh_scales, fh_min_sizes):\n","  \"\"\"Process a complete data set and save it as a TFRecord.\n","\n","  Args:\n","    name: string, unique identifier specifying the data set.\n","    directory: string, root path to the data set.\n","    num_shards: integer number of shards for this data set.\n","    synset_to_human: dict of synset to human labels, e.g.,\n","      'n02119022' --> 'red fox, Vulpes vulpes'\n","    fh_scales: Felzenzwalb-Huttenlocher segmentation scales.\n","    fh_min_sizes: Felzenzwalb-Huttenlocher min segment sizes.\n","  \"\"\"\n","  filenames, synsets, labels = _find_image_files(directory, FLAGS.labels_file)\n","  humans = _find_human_readable_labels(synsets, synset_to_human)\n","  _process_image_files(name, filenames, synsets, labels,\n","                       humans, num_shards, fh_scales, fh_min_sizes)\n","\n","\n","def _build_synset_lookup(imagenet_metadata_file):\n","  \"\"\"Build lookup for synset to human-readable label.\n","\n","  Args:\n","    imagenet_metadata_file: string, path to file containing mapping from\n","      synset to human-readable label.\n","\n","      Assumes each line of the file looks like:\n","\n","        n02119247    black fox\n","        n02119359    silver fox\n","        n02119477    red fox, Vulpes fulva\n","\n","      where each line corresponds to a unique mapping. Note that each line is\n","      formatted as <synset><tab><human readable label>.\n","\n","  Returns:\n","    Dictionary of synset to human labels, such as:\n","      'n02119022' --> 'red fox, Vulpes vulpes'\n","  \"\"\"\n","  lines = tf.gfile.GFile(imagenet_metadata_file, 'r').readlines()\n","  synset_to_human = {}\n","  for l in lines:\n","    if l:\n","      parts = l.strip().split('\\t')\n","      assert len(parts) == 2\n","      synset = parts[0]\n","      human = parts[1]\n","      synset_to_human[synset] = human\n","  return synset_to_human\n","\n","\n","def main(unused_argv):\n","  assert not FLAGS.train_shards % FLAGS.num_threads, (\n","      'Please make the FLAGS.num_threads commensurate with FLAGS.train_shards')\n","  assert not FLAGS.validation_shards % FLAGS.num_threads, (\n","      'Please make the FLAGS.num_threads commensurate with '\n","      'FLAGS.validation_shards')\n","  print('Saving results to %s' % FLAGS.output_directory)\n","\n","  # Build a map from synset to human-readable label.\n","  synset_to_human = _build_synset_lookup(FLAGS.imagenet_metadata_file)\n","\n","  fh_scales = [int(n) for n in FLAGS.fh_scales.split(',')]\n","  fh_min_sizes = [int(n) for n in FLAGS.fh_min_sizes.split(',')]\n","  assert len(fh_scales) == len(fh_min_sizes)\n","\n","  # Run it!\n","  if FLAGS.train_directory is not None:\n","    _process_dataset('train', FLAGS.train_directory, FLAGS.train_shards,\n","                     synset_to_human, fh_scales, fh_min_sizes)\n","\n","  if FLAGS.validation_directory is not None:\n","    _process_dataset('validation', FLAGS.validation_directory,\n","                     FLAGS.validation_shards, synset_to_human,\n","                     fh_scales, fh_min_sizes)\n","\n","\n","if __name__ == '__main__':\n","  tf.app.run()"],"metadata":{"id":"FJU8_UcTaBlQ","executionInfo":{"status":"error","timestamp":1651142466609,"user_tz":240,"elapsed":6554,"user":{"displayName":"Sai Charitha Akula","userId":"07906439284563601887"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fbb1891e-f6bf-4933-d048-b90a4cfd1b58"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Saving results to None\n"]},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-027d65c79801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-027d65c79801>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;31m# Build a map from synset to human-readable label.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m   \u001b[0msynset_to_human\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_synset_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_metadata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0mfh_scales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfh_scales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-027d65c79801>\u001b[0m in \u001b[0;36m_build_synset_lookup\u001b[0;34m(imagenet_metadata_file)\u001b[0m\n\u001b[1;32m    580\u001b[0m       \u001b[0;34m'n02119022'\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m->\u001b[0m \u001b[0;34m'red fox, Vulpes vulpes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m   \"\"\"\n\u001b[0;32m--> 582\u001b[0;31m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagenet_metadata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m   \u001b[0msynset_to_human\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mreadlines\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m\"\"\"Returns all lines from the file in a list.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     76\u001b[0m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0;32m---> 77\u001b[0;31m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: imagenet_metadata.txt; No such file or directory"]}]}]}